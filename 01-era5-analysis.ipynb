{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd6a99b-34ba-4af4-816c-64b09fab2c24",
   "metadata": {},
   "source": [
    "# ERA5 Analysis Demo\n",
    "\n",
    "ERA5 is a weather reanalysis produced by ECMWF, providing hourly estimates of atmospheric and land variables from 1940-present at ~0.25 deg resolution. The complete dataset is approximately 1PB in size. For this demo however, we're going to use a subset of the data that includes 18 surface fields from 1975-2024.\n",
    "\n",
    "The goals of the demo are to show participants how to:\n",
    "\n",
    "1. Use Arraylake to discover and access datasets\n",
    "2. Use Icechunk and Xarray to access the ERA5 dataset directly from cloud object storage\n",
    "3. Explore Icechunk's version history\n",
    "4. Create a subset of the ERA5 dataset and write it to a new Icechunk repo\n",
    "\n",
    "We'll start by importing the Python libraries we need for the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93201839-7f8f-46d9-866a-3debcf7a43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arraylake import Client\n",
    "\n",
    "import xarray as xr\n",
    "from dask.diagnostics import ProgressBar\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3331dbc5-e14f-4398-9041-e091838c9dc9",
   "metadata": {},
   "source": [
    "## Authenticate with Arraylake\n",
    "\n",
    "The Arraylake platform utilizes OAuth2-style authentication. This allows us to govern access to datasets based on individual user's identity. The datasets we'll be using today are all public but when you create your own Icechunk repo, it will be private (by default).\n",
    "\n",
    "Instructions: after running the cell below, open the link provided and follow the login instructions. Use the email address you registered for the hackweek with. If your email is associated with a Google Workspace or GMail account, you can use that to login as well.\n",
    "\n",
    "Note that you'll have to login separately to the Arraylake web app: https://app.earthmover.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd96dd-da4e-4bfc-92eb-c3cccbc198df",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d38536-e2ee-4c4a-b644-3340fd272df3",
   "metadata": {},
   "source": [
    "## Discovering data\n",
    "\n",
    "In addition to using the Arraylake Web App to explore the catalog of data, we can use the Arraylake Client to discover datasets in our any organization we are allowed to view. Here we'll list the contents of the `earthmover-public` organization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89902563-e0d5-4a36-841c-d13ed8b667f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = client.list_repos('ICESAT-2HackWeek')\n",
    "repos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c679ac-ae77-46f4-9cfa-8c9ebdbcd8de",
   "metadata": {},
   "source": [
    "## Accessing data\n",
    "\n",
    "We will come back to the ICESat data in the next notebook. For now, we're going to work with the ERA5 surface dataset in the Earthmover-public organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e7017-3109-482d-910d-a91fc3eba6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = client.get_repo(\"earthmover-public/era5-surface-aws\")  # get the icechunk repository\n",
    "session = repo.readonly_session(\"main\")                       # checkout a read-only session\n",
    "era5 = xr.open_zarr(session.store, group=\"spatial\")           # open the dataset with Xarray\n",
    "\n",
    "display(era5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc89deb-667e-4459-aa8b-811c08f71a9b",
   "metadata": {},
   "source": [
    "Now that we've opened this dataset with Xarray, we can immediately start querying it. Below, we'll make a simple plot from the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4450b6-3d96-4723-8d06-42f665068d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can immediately start querying this dataset\n",
    "da = era5['t2'].sel(time='2024-08-20T23')\n",
    "da.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17887c8f-71d2-4307-b786-ad467a5cd3ba",
   "metadata": {},
   "source": [
    "Of course, because we're now working with Xarray, we can pull in other parts of the open source ecosystem. For example, in the next cell, we'll turn the above plot into a nicely formatted map using Cartopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f501c360-a2d2-4d2e-9207-bd861e187348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Cartopy, we can polish this plot a bit further\n",
    "plot_kws = dict(\n",
    "    transform=ccrs.PlateCarree(), \n",
    "    subplot_kws=dict(projection=ccrs.Robinson()),\n",
    "    cbar_kwargs={'orientation': 'horizontal', 'shrink': 0.8, 'pad': 0.1}\n",
    ")\n",
    "\n",
    "p = da.plot(robust=True, **plot_kws)\n",
    "\n",
    "p.axes.set_global()\n",
    "p.axes.coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fd028-eb70-4654-8dcc-1e7a58fce674",
   "metadata": {},
   "source": [
    "## Exercise 1 -- Plot the Dec 2021 average snowdepth over the northern hemisphere\n",
    "\n",
    "In the cell below, plot the average snowdepth from Dec 2021 in the Northern Hemisphere. \n",
    "\n",
    "***Hint: you'll need to use Xarray to sub-select and process the correct part of the dataet using the `.sel` and `.mean` methods.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987eba8a-1336-4e41-ba2a-658fba702346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67fa2b90-189d-4c1e-8ceb-18f4db1fd1e5",
   "metadata": {},
   "source": [
    "## Trend Analysis\n",
    "\n",
    "We can also use Xarray to help us calculate the estimate temperature trends in the ERA5 dataset. We'll use the `temporal` group in our Icechunk store which has the same data, just chunked differently to upport more efficeint time-series queries.\n",
    "\n",
    "***Hint: if you are running on a smaller computer or VM, you may want to further limit the spatial area or time bounds in the example below.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0507d6c-3136-45dc-b75f-8d58fd61d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5 = xr.open_zarr(session.store, group=\"temporal\")           # open the dataset with Xarray\n",
    "\n",
    "# 1. Greenland region extraction (efficient spatial subsetting)\n",
    "greenland = era5.sel(latitude=slice(85, 59), longitude=slice(290, 350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407cfe21-4cd9-4a38-9659-16faef8206dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    t2_trend = greenland['t2'].groupby('time.year').mean().polyfit('year', 1, skipna=True).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ec2e6-7151-4c98-a2ba-6384a1c6811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_analysis['t2'].polyfit_coefficients.isel(degree=0).plot(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacfd4a2-8def-4d1c-ac69-2b12b496f2ff",
   "metadata": {},
   "source": [
    "## Exercise 2 -- Calculate the trend in peak winter snowfall over Alaska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e645940-30bb-46c8-9cd4-5b91a14f6f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c31880d-e8d4-4634-a96c-ed7577382b65",
   "metadata": {},
   "source": [
    "## Back to Icechunk\n",
    "\n",
    "Now that we've got our hands dirty with Xarray+Icechunk, let's come back to some of the Icechunk features we skipped past earlier on. We're specifically interested here in exploring the version history of the ERA5 repository. Let's start by listing the branches in the repository then looking at the commit history (aka ancestry):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9becb9b6-03d3-4d65-97cb-d27fde399d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.list_branches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3c3c3-33a5-4701-bc43-50cdfd658d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = repo.ancestry(branch=\"main\")\n",
    "for ancestor in hist:\n",
    "    print(ancestor.id, ancestor.message, ancestor.written_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b413eb6-d46c-48b5-953c-41071e522a21",
   "metadata": {},
   "source": [
    "Inspecting this version history, we can see how the dataset was constructed! \n",
    "\n",
    "## Excersise 3 -- checkout the repository at a prior snapshot\n",
    "\n",
    "***Hint: `repo.readonly_session` takes a `snapshot_id` parameter.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d025a7-c33e-499a-bbc9-c7e911283a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.readonly_session?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba93e0a-97a9-48bb-b5e3-9fcdcd692711",
   "metadata": {},
   "source": [
    "## Write your first Icechunk repo\n",
    "\n",
    "As the final part of this notebook, we're each going to write our first Icechunk repo to Arraylake. \n",
    "\n",
    "***Hint: I recommend keeping your subset of ERA5 relatively small - particularly if you are on a small VM.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf052d53-84b5-4293-a3e5-09ce5c6211ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create your first icechunk dataset\n",
    "\n",
    "org = 'ICESAT-2HackWeek'\n",
    "my_name = 'jhamman'  # <-- put your name or github id here\n",
    "\n",
    "repo = client.create_repo(f'{org}/era5-subset-{my_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeaf9af-5df5-461c-b363-beb9ba0bebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = repo.writable_session('main')\n",
    "\n",
    "# bonus -- replace the greenland dataset with a subset of ERA5 that is more interesting to you!\n",
    "subset = greenland[['t2', 'tcc']].isel(time=slice(24)).drop_encoding().load()\n",
    "\n",
    "subset.to_zarr(session.store, zarr_format=3, consolidated=False, mode='w')\n",
    "\n",
    "# inspect the status of your session before commiting\n",
    "session.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de064da-ab6b-495b-bfa5-8132e2e63cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit('🧊 my first icechunk commit! 🚀')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb310b8-666f-485f-aaec-fcbace90e5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
